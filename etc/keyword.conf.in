# common:
root = @BAMBOO_ROOT@
max_token_length = 8
verbose = 1

_use_single_combine = 1
_use_break = 0
#_ner_chain = crf_ner_np

# models and lexicons
crf_seg_model = $root/index/crf_seg.model
number_trailing_lexicon = $root/index/number_trailing.idx
single_combination_lexicon = $root/index/user_combine.idx
break_lexicon = $root/index/break.idx
#crf_ner_np_model = $root/index/crf_ner_np.model

# dict of keyword extractor
ke_token_aff_dict = $root/index/token_aff_dict.idx
ke_token_id_dict = $root/index/token_id.idx
ke_token_df_dict = $root/index/token_df.idx
ke_filter_dict = $root/index/filter_word.idx

# build top_n keywords of text
ke_top_n = 10

# algorithm
ke_algorithm = graph
#ke_algorithm = tfidf

# general
# weight(token) = 
# 	( ke_firstocc_w * exp( - first_occ(token) / ke_firstocc_t )
# 	+ ke_numocc_w * log1p(num_occ(token) / ke_numocc_s) + ke_numocc_t
#	+ is_title(token) * ke_title_weight )
#	+ is_ner(token) * ke_ner_weight )
#	* IDF(token)
# IDF(token) = ke_idf_t + ke_idf_w * log1p( D/DF(token) )
ke_title_weight = 7
ke_ner_weight = 7
ke_feature_min_length = 3
ke_feature_min_utf8_length = 2
ke_firstocc_w = 6
ke_firstocc_t = 40
ke_numocc_w = 4
ke_numocc_s = 1
ke_numocc_t = 5
ke_idf_w = 1
ke_idf_t = 1

# for graph rank
ke_wordrank_eta = 0.00015
ke_wordrank_alpha = 0.7
ke_wordrank_beta = 0.3
ke_wordrank_maxiter = 5

# for training
ke_freq_threshold = 2
ke_df_threshold = 2
ke_word_top_relation = 20

# punctuation to segment sentence
ke_punctuation = 。？！?!，,；;
#，；-.


# Module: single_combine
combine_koko = 0
combine_forward = 1
combine_backward = 1
combine_neighbor = 1

# Module: break
break_min_length = 5

# Module: unigram
ele_lambda = 0.5

